### Contents
1. [Installation](#installation)
2. [Demo](#Demo)
3. [Preparation](#Preparation)
4. [Eval](#Eval)
5. [Performance](#Performance)
6. [Model info](#Model info)

### Installation
1. Get the code. We will call the directory that you cloned Caffe into `$CAFFE_ROOT`
    **Note:** To download caffe-linx

  ```shell
  unzip caffe-xilinx.zip
  cd caffe-xilinx
  ```

2. Build the code. Please follow [Caffe instruction](http://caffe.berkeleyvision.org/installation.html) to install all necessary packages and build it.
  ```shell
  # Modify Makefile.config according to your Caffe installation.
  cp Makefile.config.example Makefile.config
  make -j8
  # Make sure to include $CAFFE_ROOT/python to your PYTHONPATH.
  # python version(python2)
  make py
  ```

Note: If you are in the released Docker env, there is no need to build Caffe.

### Demo
 run demo
  ```shell
  # modify the "caffe_xilinx_dir" in code/test/demo.sh
  sh code/test/demo.sh
  ```
### Preparation
1. Download [MPII Human Pose Dataset](http://human-pose.mpi-inf.mpg.de/)

2. Download [mpii_annotations.json](https://drive.google.com/open?id=1mQrH_yVHeB93rzCfyq5kC9ZYTwZeMsMm) and save it to `data/mpii`

### Eval
1. Evaluate the most recent snapshot.

  test the images 
  ```shell
  # If you would like to test a model you trained, you can do:
  # 1. add the all images path to  images.txt and  run 
  # 2. modify the threshlod 0.3 to 0.005 
  sh code/test/demo.sh
  ```
  Evaluate PCK@0.5. (set scale as a constant value 6.3)
  ```shell
  # Evaluate PCK@0.5
  # Ensure that the image name is consistent
  python code/test/evaluation.py --data image_path/ --caffe caffe_path/ --weights ./float/test.caffemodel --model ./float/test.prototxt --anno anno_path/mpii_annotations.json
  ```
  For quantized model evaluation
   ```shell
  # Evaluate PCK@0.5
  # Ensure that the image name is consistent
  python code/test/evaluation.py --data image_path/ --caffe caffe_path/ --weights ./quantized/quantize_train_test.caffemodel --model ./quantized/quantize_test.prototxt --anno anno_path/mpii_annotations.json
   ```
### Performance
  ```shell
   Test images: MPII Human Pose Dataset
   Model: hourglass float
   PCK@0.5: 87.1826%
   Model: hourglass INT8
   PCK@0.5: 86.6052%
  ```
### Model info
1. data preprocess
```
1. data channel order: RGB(0~255)                  
2. resize: 256 * 256(H * W) 
3. mean_value: 112.7424, 113.664, 110.7712
4. scale: 0.00390625
```
2.For quantization with calibration mode:
  ```
  Modify datalayer of test.prototxt for model quantization:
  a. Replace the "Input" data layer of test.prototxt with the "ImageData" data layer.
  b. Modify the "ImageData" layer parameters according to the data preprocess information.
  c. Provide a "quant.txt" file, including image path and label information with fake value(like 1).
  d. Give examples of data layer and "quant.txt":
  # data layer example
  layer {
    name: "data"
    type: "ImageData"
    top: "data"
    top: "label"
    include {
      phase: TRAIN
    }
    transform_param {
      mirror: false
      mean_value: 112.7424
      mean_value: 113.664
      mean_value: 110.7712
      scale: 0.00390625
     }

    image_data_param {
      source: "quant.txt"
      new_width: 256  
      new_height: 256
      batch_size: 16
    }
  }
  # quant.txt: image path label
    images/000001.jpg 1
    images/000002.jpg 1
    images/000003.jpg 1

  ```
3.For quantization with finetuning mode: 
  ```
  use test.prototxt for model quantization.
  ```
4.For deployment, modify "deploy.prototxt" generated by quantizer
  ```
  1. replace first layer with the following input layer:
layer {
  name: "data"
  type: "Input"
  top: "data"
  transform_param {
    mean_value: 112.7424
    mean_value: 113.664
    mean_value: 110.7712
    scale: 0.00390625
  }
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 256
      dim: 256
    }
  }
}
  ```

### Reference
[pytorch-pose](https://github.com/bearpaw/pytorch-pose)


